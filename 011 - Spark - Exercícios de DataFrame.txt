Spark - Exercícios de DataFrame

1. Enviar o diretório local “/input/exercises-data/juros_selic” para o HDFS em “/user/aluno/<nome>/data”

hdfs dfs -put input/exercises-data/juros_selic/ /user/aluno/heliton/data

2. Criar o DataFrame jurosDF para ler o arquivo no HDFS “/user/aluno/<nome>/data/juros_selic/juros_selic.json”

val jurosDF = spark.read.json("/user/aluno/heliton/data/juros_selic/juros_selic.json")

3. Visualizar o Schema do jurosDF

jurosDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)

4. Mostrar os 5 primeiros registros do jurosDF

jurosDF.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/06/1986| 1.27|
|01/07/1986| 1.95|
|01/08/1986| 2.57|
|01/09/1986| 2.94|
|01/10/1986| 1.96|
+----------+-----+

5. Contar a quantidade de registros do jurosDF

jurosDF.count()
res5: Long = 393

6. Criar o DataFrame jurosDF10 para filtrar apenas os registros com o campo “valor” maior que 10

val jurosDF10 = jurosDF.where("valor > 10")
jurosDF10: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [data: string, valor: string]

jurosDF10.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+

7. Salvar o DataFrame jurosDF10  como tabela Hive “<nome>.tab_juros_selic”

jurosDF10.write.saveAsTable("heliton.tab_juros_selic")

Para sobrescrever existente
jurosDF10.write.mode("append").saveAsTable("heliton.tab_juros_selic")

8. Criar o DataFrame jurosHiveDF para ler a tabela “<nome>.tab_juros_selic”

val jurosHiveDF = spark.read.table("heliton.tab_juros_selic")
jurosHiveDF: org.apache.spark.sql.DataFrame = [data: string, valor: string]

9. Visualizar o Schema do jurosHiveDF

jurosHiveDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)

10. Mostrar os 5 primeiros registros do jurosHiveDF

jurosHiveDF.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows

11. Salvar o DataFrame jurosHiveDF no HDFS no diretório “/user/aluno/nome/data/save_juros” no formato parquet

jurosHiveDF.write.save("/user/aluno/heliton/data/save_juros")

12. Visualizar o save_juros no HDFS

hdfs dfs -ls /user/aluno/heliton/data/save_juros

13. Criar o DataFrame jurosHDFS para ler o diretório do “save_juros” da questão 8

val jurosHDFS = spark.read.load("/user/aluno/heliton/data/save_juros")
jurosHDFS: org.apache.spark.sql.DataFrame = [data: string, valor: string]

14. Visualizar o Schema do jurosHDFS

jurosHDFS.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)

15. Mostrar os 5 primeiros registros do jurosHDFS

jurosHDFS.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows








